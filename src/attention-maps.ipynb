{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the attention of VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total x-ray records:112120.\n",
      "Labels (13:[('Atelectasis', 11559), ('Cardiomegaly', 2776), ('Consolidation', 4667), ('Edema', 2303), ('Effusion', 13317), ('Emphysema', 2516), ('Fibrosis', 1686), ('Infiltration', 19894), ('Mass', 5782), ('Nodule', 6331), ('Pleural_Thickening', 3385), ('Pneumonia', 1431), ('Pneumothorax', 5302)])\n",
      "Total x-ray records:80000.\n",
      "Total x-ray records:112120.\n",
      "Labels (13:[('Atelectasis', 11559), ('Cardiomegaly', 2776), ('Consolidation', 4667), ('Edema', 2303), ('Effusion', 13317), ('Emphysema', 2516), ('Fibrosis', 1686), ('Infiltration', 19894), ('Mass', 5782), ('Nodule', 6331), ('Pleural_Thickening', 3385), ('Pneumonia', 1431), ('Pneumothorax', 5302)])\n",
      "Total x-ray records:80000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/src/train.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  lambda x: x['Finding Labels'].split('|'), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12918 images belonging to 13 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as MobileNet_preprocess_input\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as VGG19_preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as InceptionResNetV2_preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as InceptionV3_preprocess_input\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as MobileNetV2_preprocess_input\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.nasnet import preprocess_input as NASNetLarge_preprocess_input\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import data_preparation\n",
    "import params\n",
    "import os\n",
    "import reset\n",
    "import gradient_accumulation\n",
    "from utils import plot_train_metrics, save_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from train import create_data_generator, _create_base_model, create_simple_model, create_attention_model\n",
    "\n",
    "metadata = data_preparation.load_metadata()\n",
    "metadata, labels = data_preparation.preprocess_metadata(metadata)\n",
    "train, valid = data_preparation.stratify_train_test_split(metadata)\n",
    "\n",
    "# for these image sizes, we don't need gradient_accumulation to achieve BATCH_SIZE = 256\n",
    "optimizer = 'adam'\n",
    "if params.DEFAULT_OPTIMIZER != optimizer:\n",
    "    optimizer = gradient_accumulation.AdamAccumulate(\n",
    "        lr=params.LEARNING_RATE, accum_iters=params.ACCUMULATION_STEPS)\n",
    "\n",
    "base_models = [\n",
    "        [VGG19, params.VGG19_IMG_SIZE, VGG19_preprocess_input],\n",
    "        #[MobileNet, params.MOBILENET_IMG_SIZE, MobileNet_preprocess_input],\n",
    "        #[InceptionResNetV2, params.INCEPTIONRESNETV2_IMG_SIZE,\n",
    "        # InceptionResNetV2_preprocess_input],\n",
    "        \n",
    "        #[InceptionV3, params.INCEPTIONV3_IMG_SIZE, InceptionV3_preprocess_input],\n",
    "        #[MobileNetV2, params.MOBILENETV2_IMG_SIZE, MobileNetV2_preprocess_input],\n",
    "        #[NASNetLarge, params.NASNETLARGE_IMG_SIZE, NASNetLarge_preprocess_input],\n",
    "    ]\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def plot_attention_map(_Model, input_shape, transfer_learing,\n",
    "                preprocessing_function,\n",
    "                train, valid, labels,\n",
    "                extend_model_callback, optimizer,\n",
    "                name_prefix, weights=\"imagenet\"):\n",
    "\n",
    "    test_X, test_Y = next(create_data_generator(\n",
    "        valid, labels, 100, None, target_size=input_shape))\n",
    "    \n",
    "    baseModel = _create_base_model(_Model,\n",
    "                                   labels,\n",
    "                                   test_X.shape[1:],\n",
    "                                   trainable=False,\n",
    "                                   weights=None)\n",
    "\n",
    "    model = extend_model_callback(baseModel, labels, optimizer)\n",
    "    model_name = name_prefix+'_' + baseModel.name\n",
    "\n",
    "    weights = os.path.join(params.RESULTS_FOLDER,\n",
    "                           model_name, 'weights.best.hdf5')\n",
    "\n",
    "    print('Loading '+weights)\n",
    "    model.load_weights(weights, by_name=True)\n",
    "    model.trainable = False\n",
    "\n",
    "    # Get the attention model first\n",
    "    for attention_model in model.layers:\n",
    "        c_shape = attention_model.get_output_shape_at(0)\n",
    "        if c_shape[-1]==13:\n",
    "            break\n",
    "    # now get the attention layer\n",
    "    for attention_layer in attention_model.layers:\n",
    "        c_shape = attention_layer.get_output_shape_at(0)\n",
    "        if len(c_shape)==4:\n",
    "            if c_shape[-1]==1:\n",
    "                break\n",
    "\n",
    "    rand_idx = np.random.choice(range(len(test_X)), size = 12)\n",
    "    attention_function = K.function(inputs = [attention_model.get_input_at(0), K.learning_phase()],\n",
    "               outputs = [attention_layer.get_output_at(0)]\n",
    "              )\n",
    "    fig, m_axs = plt.subplots(len(rand_idx), 2, figsize = (8, 4*len(rand_idx)))\n",
    "    [c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for c_idx, (img_ax, attn_ax) in zip(rand_idx, m_axs):\n",
    "        cur_img = test_X[c_idx:(c_idx+1)]\n",
    "        cur_features = baseModel.predict(cur_img)\n",
    "        attn_img = attention_function([cur_features, 0])[0]\n",
    "        img_ax.imshow(cur_img[0,:,:,0], cmap = 'bone')\n",
    "        attn_ax.imshow(attn_img[0, :, :, 0], cmap = 'viridis', \n",
    "                       vmin = 0, vmax = 1, \n",
    "                       interpolation = 'lanczos')\n",
    "        real_label = test_Y[c_idx]\n",
    "        \n",
    "        indices=np.argwhere(np.array(real_label) > 0.5).ravel()\n",
    "        img_ax.set_title('Classes\\n%s' % (labels[indices]))\n",
    "        pred_confidence = model.predict(cur_img)[0]\n",
    "        pred_confidence = np.array(pred_confidence)\n",
    "        \n",
    "        pred_confidence = pred_confidence[:].astype(float)\n",
    "        pred_confidence = 100*pred_confidence\n",
    "        string_confidence = ''\n",
    "        for index in indices:\n",
    "            string_confidence = string_confidence + '%2.1f%% ' % (pred_confidence[index])\n",
    "        #print(string_confidence)\n",
    "        attn_ax.set_title('Attention Map\\nConfidence:'+string_confidence)\n",
    "    \n",
    "    attention_figure = os.path.join(params.RESULTS_FOLDER, model_name, 'attention_map.png')\n",
    "    fig.savefig(attention_figure, dpi = 300)\n",
    "    \n",
    "    print('Saved plot at'+attention_figure)\n",
    "\n",
    "    \n",
    "metadata = data_preparation.load_metadata()\n",
    "metadata, labels = data_preparation.preprocess_metadata(metadata)\n",
    "train, valid = data_preparation.stratify_train_test_split(metadata)\n",
    "\n",
    "# for these image sizes, we don't need gradient_accumulation to achieve BATCH_SIZE = 256\n",
    "optimizer = 'adam'\n",
    "if params.DEFAULT_OPTIMIZER != optimizer:\n",
    "    optimizer = gradient_accumulation.AdamAccumulate(\n",
    "        lr=params.LEARNING_RATE, accum_iters=params.ACCUMULATION_STEPS)\n",
    "\n",
    "unfrozen = 'unfrozen_'\n",
    "if True:\n",
    "    unfrozen = ''\n",
    "custome_layers = [\n",
    "    [create_attention_model, unfrozen+'latest_attention'],\n",
    "    #[create_simple_model, unfrozen+'latest_simple'],\n",
    "]\n",
    "\n",
    "for [custome_layer, name_prefix] in custome_layers:\n",
    "    for [_Model, input_shape, preprocess_input] in base_models:\n",
    "        plot_attention_map(_Model, input_shape, True , preprocess_input,\n",
    "                    train, valid, labels,\n",
    "                    custome_layer, optimizer, name_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
